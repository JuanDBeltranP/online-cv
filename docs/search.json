[
  {
    "objectID": "work.html",
    "href": "work.html",
    "title": "Work Experience",
    "section": "",
    "text": "Currently leading the data science team at the Research department in ECOM, my journey has been marked by pivotal contributions to our core product offerings.\nI’ve played a significant role in the development and maintenance of advanced trading signal models that leverage Supply & Demand dynamics, weather data, and historical price trends. This unique blend of information allows us to predict market behaviour with high precision, creating a strategic advantage in our trading operations.\nRecognizing the critical importance of sustainability in today’s market, I’ve been instrumental in developing a new framework for measuring deforestation on global farms. This initiative highlights our commitment to responsible trading and provides invaluable insights into environmental impact.\nTo further streamline our processes and ensure data integrity, I’ve implemented an automated alert system that identifies potential anomalies in cotton, coffee and cocoa price data. This system proactively sends email alerts when irregularities are detected, allowing us to swiftly mitigate potential risks and maintain market-leading accuracy in our data-driven decisions.\n\nSenior Data Scientist | ECOM Trading | Dec 2019 - Nov 2022\n\nLed the developments of a comprehensive suite of data products, encompassing dashboards, automatic reports, and web applications in the research department as a senior data scientist.\nDeveloped an array of machine learning models to tackle key industry questions, from predicting the supply and demand of commodities like coffee, cotton, and cocoa to estimating crop yields using satellite imagery.\nUtilized my predictive models to forecast a range of pivotal factors, including the productivity of West African cocoa farms, the medium-term climate change effects on global plantations, and future price dynamics based on climatic variables.\nConceived an innovative web application that fused historical deforestation data with georeferenced farm locations, forming a unique deforestation risk model for global farms.\n\nProduct Developer - Data Science | Decoded | Oct 2018 - Nov 2019\n\nPioneered and executed over 40% of the curriculum for Decoded’s flagship offering, the Data Academy, fostering data science integration among blue-chip clients, including Societe General, UBS, Unilever, Nike, and M&S.\nCrafted comprehensive course material covering fundamental coding in Python and R, advanced statistics, and a wide array of machine learning techniques.\nAuthored specialized R and Python modules for an extensive range of topics such as regression analysis, classification methods, neural networks, Big Data handling, time series analysis, and SQL.\nRegularly hosted workshops to impart these modules to client employees, both in-person and via webinars, and trained new facilitators to carry the torch forward.\n\nResearch Associate - Data Science | Institute for Risk and Disaster Reduction, University College London | Jan 2018 - Oct 2018\n\nDeveloped a machine learning model capable of real-time prediction of potential mosquito breeding points across four cities in Brazil, employing Python, TensorFlow, and Keras to create recurrent neural networks that geospatially modelled virus and mosquito occurrences.\nThe results of my work were manifested in a user-friendly bokeh web application, which I built and was actively used by health professionals in Brazil.\nComplimenting this, I also created a mobile application to streamline data collection from health professionals on the ground."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr Juan D. Beltran",
    "section": "",
    "text": "I have been coding in R for the last 15 years and in Python for the last 9 years. I have designed, developed and maintained a wide range of data products which combine machine learning models and GIS analysis in the shape of stand alone models, dashboards, advanced visualisation, automatic reports, and web apps. I have extensive knowledge in statistical modelling, forecasting time series and geospatial analysis."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "2017: Yang X, Hu R, Yin H, Jenkins J, Shu S, Tang H, Liu D, Weighill DA, Ha J, Heyduk K, Goodstein DM, Guo H, Moseley RC, Fitzek E, Jawdy S, Zhang Z, Xie M, Hartwell J, Grimwood J, Abraham PE, Mewalal R, Yim WC, Beltrán JD, Boxall SF, Dever LV, Palla KJ, Albion R, Garcia T, Mayer J, Lim SD, Wai CM, Van Buren R, De Paoli HC, Borland AM, Guo H, Chen J, Muchero W, Yin Y, Jacobson DA, Tschaplinski TJ, Hettich RL, Ming R , Winter K , Leebens-Mack JH, Smith JAC, Cushman J, Schmutz J, Tuskan GA.: Kalanchoë genome reveals convergent evolution of crassulacean acid metabolism. Nature Communications 8: 1899\n2015: Yang X, Cushman JC, Borland AM, Edwards EJ, Wullschleger SD, Tuskan GA, Owen NA, Griffiths H, Smith JAC, De Paoli HC, Weston DJ, Cottingham R, Hartwell J, Davis SC, Silvera K, Ming R, Schlauch K, Abraham P, Stewart JR, Guo H, Albion R, Ha J, Lim SD, Wone BWM, Yim WC, Garcia T, Mayer JA, Petereit J, Nair SS, Casey E, Hettich RL, Ceusters J, Ranjan P, Palla KP, Yin H, Reyes-García C, Andrade JL, Freschi L, Beltrán JD, Dever LV, Boxall SF,Waller J, Davies J, Bupphada P, Kadu N, Winter K, Sage RF, Aguilar CN, Schmutz J, Jenkins J, Holtum JAM. A roadmap for research on crassulacean acid metabolism (CAM) to enhance sustainable food and bioenergy production in a hotter, drier world. New Phytologist 207:491–504.\n2014: Poster presentation, “Evolutionary origins and ecophysiology of CAM photosynthesis in the montane genus Puya (Bromeliaceae)”, 34 th New Phytologist Symposium “Plant Systems Biology and Ecology of CAM plants”, Lake Tahoe, Tahoe City, CA, USA, 15–18 July 2014.\n2013: Beltrán JD., Lasso E., Madriñán S., Virgo A., Winter K.: Juvenile tank-bromeliads lacking tanks: Do they engage in CAM photosynthesis?, Photosynthetica 51: 55–62.\n2012: M.Sc. Thesis: CAM or not CAM: A study on juveniles of Guzmania lingulata, Guzmania monostachia and Werauhia sanguinolenta (Bromeliaceae), Universidad de los Andes.\n2010: B.Sc. Thesis: Evolution of xerophyte habit in the tribe Tillandsieae (Bromeliaceae): a phylogenetic approach, Universidad de los Andes."
  },
  {
    "objectID": "juan.html",
    "href": "juan.html",
    "title": "Summary",
    "section": "",
    "text": "I have several years of experience working as a data scientist in different industries. Advanced knowledge of machine learning, time series analysis, and GIS. Significant experience programming in Python and R."
  },
  {
    "objectID": "juan.html#project-management",
    "href": "juan.html#project-management",
    "title": "Summary",
    "section": "Project Management",
    "text": "Project Management\nI have experience establishing and working as a part of cross-functional teams. I have worked with Agile methodology and continuous integration/continuous delivery principles."
  },
  {
    "objectID": "juan.html#presentation-data-visualisation",
    "href": "juan.html#presentation-data-visualisation",
    "title": "Summary",
    "section": "Presentation & Data Visualisation",
    "text": "Presentation & Data Visualisation\nI have strong experience building dashboards,reports and presentations for wider audiences using RMarkdown, Shiny and Bokeh. Recent experience using Quarto (which I used to build my CV). I have presented my results in academic and commercial journals. I run a journal club in the research department."
  },
  {
    "objectID": "juan.html#leadership",
    "href": "juan.html#leadership",
    "title": "Summary",
    "section": "Leadership",
    "text": "Leadership\nI have been mentoring juniors peers and acting as a data advocate across multiple teams in my current and previous roles. I have researched difficult problems with curiosity and rigour. I have been designing technical interviews and explaining complex concepts to stakeholders with clarity and empathy."
  },
  {
    "objectID": "education.html",
    "href": "education.html",
    "title": "Education",
    "section": "",
    "text": "Dr Juan D Beltran:\nContact Information: - Email: jd.beltran43@gmail.com - Phone: 07922857788 - LinkedIn: https://www.linkedin.com/in/jdbeltran/\nObjective: A seasoned Lead Data Scientist adept in translating complex data into actionable insights that underpin strategic business decisions. With extensive experience across a wide range of data science tools and methodologies, I seek to apply my expertise and innovative approach to data to drive organizational success and digital transformation.\nSkills: - Machine Learning - Python, R, SQL, Apache Spark, TensorFlow, Keras - GIS Analysis - Project Management - Curriculum Development - Stakeholder Engagement\nExperience:\nLead Data Scientist, ECOM Trading | Dec 2022 - Present - Lead the data science team within the research department, developing and maintaining various data products and machine learning models. - Developed a global deforestation risk model by integrating historical deforestation data and georeferenced farm locations. - Established an automated email alert system for potential anomalies in cotton/coffee/cocoa prices. - Championed ECOM’s digital transformation by fostering the adoption of data science approaches across different business areas.\nSenior Data Scientist, ECOM Trading | Dec 2019 - Nov 2022 - Successfully forecasted supply and demand trends for coffee, cotton, and cocoa. - Developed models predicting the productivity of cocoa farms in West Africa and the future impact of climate change on coffee and cocoa plantations worldwide. - Utilized machine learning and satellite images to estimate crop yields.\nProduct Developer - Data Science, Decoded | Oct 2018 - Nov 2019 - Designed over 40% of the Data Academy curriculum, teaching blue-chip clients advanced data science techniques. - Authored various Python and R modules covering a wide spectrum of data science concepts. - Regularly conducted workshops and webinars to teach modules to students across various companies. - Trained new facilitators to deliver the created modules.\nResearch Associate - Data Science, Institute for Risk and Disaster Reduction, University College London | Jan 2018 - Oct 2018 - Developed a machine learning model to predict mosquito breeding points across four cities in Brazil in real time. - Displayed the results in a bokeh web app, used by health professionals in Brazil. - Developed a mobile app to collect data from health professionals in Brazil.\nEducation:\nPhD (DPhil), Plant Sciences, University of Oxford | 2013 - 2017 - Utilized machine learning, computational modelling, and advanced statistics to study plant behavior under drought stress and the impact of climate change on plant species distribution. - Employed Neural Networks, XGBoost, Random Forest, Clustering analysis, A/B tests using bootstrapping and Bayesian statistics.\nMSc, Biology (1st place), Universidad de los Andes (Colombia) | 2012 - Leveraged R to test hypotheses concerning biochemical changes in juvenile plants under drought conditions.\nBSc, Biology, Universidad de los Andes (Colombia) | 2010 - Gained proficiency in R during biostatistics coursework and applied it extensively in my dissertation and subsequent work.\nAwards: - Weidenfeld Scholarship and Leadership Program for D.Phil. Funding, University of Oxford | 2013-2016 - Scholarship from Administrative Department of Science, Technology and Innovation (Colombia) for D.Phil. Funding, University of Oxford | 2013-2017 - Winner of New Phytologist Poster Prize (1st place), 34th New Phytologist Symposium “Plant Systems Biology and Ecology of CAM plants”, California, U.S.A. | 2014"
  },
  {
    "objectID": "Notes/MLOPS0.html",
    "href": "Notes/MLOPS0.html",
    "title": "Introduction to MLOps",
    "section": "",
    "text": "In today’s blog, I will discuss a pivotal concept in modern machine learning architectures: MLOps, short for Machine Learning Operations.\n\n\nMLOps is a set of best practices combining Machine Learning (ML), Data Engineering, and DevOps. The goal of MLOps is to streamline and standardize the machine learning lifecycle, from development and deployment to maintenance.\nMLOps aims to address various challenges in operationalizing ML models, such as managing data dependencies, maintaining code quality, ensuring model reproducibility, and monitoring model performance over time.\n\n\n\nLet’s dive deeper into the various components that constitute MLOps:\n\n\nVersion control is essential for tracking changes to code, data, parameters, and environment configuration. Git is often used for code, but tools like DVC (Data Version Control) can help manage data and model versions.\n\n\n\nTesting ensures the stability and reliability of the code, including model code and infrastructure code. Types of tests include unit tests, integration tests, and end-to-end tests. Additionally, data validation tests are crucial to ensure the quality of the data feeding into the models.\n\n\n\nCI is a practice where developers frequently merge their code changes into a central repository. After each merge, automated builds and tests are run. In the context of MLOps, this includes integration tests of ML code, infrastructure, and data pipelines.\n\n\n\nContinuous Deployment is the practice of automatically deploying the code to production after passing the build and test stages. For ML, this also includes model training, validation, and deployment.\n\n\n\nModel performance needs to be monitored over time to ensure it doesn’t degrade. Monitoring systems can track model performance metrics and provide alerts for any significant changes. Logging systems keep detailed records of data inputs and outputs, model predictions, and any errors or exceptions.\n\n\n\nEnsuring the same results can be achieved if a past version of the model is re-run with the same data and parameters is key. This includes versioning data, code, and environment, as Ill as tracking all experiments.\n\n\n\n\nSeveral tools and platforms help facilitate MLOps, including:\n\nMLflow: An open-source platform for managing the end-to-end ML lifecycle, including experimentation, reproducibility, and deployment.\nTFX (TensorFlow Extended): A Google-production-scale ML platform that provides a configuration framework and shared libraries to integrate common components needed to define, launch, and monitor ML systems.\nKubeflow: An open-source project dedicated to making deployments of machine learning workflows on Kubernetes simple, portable, and scalable.\nSeldon: An open-source platform that enables businesses to deploy, scale, and optimize machine learning models in production.\n\n\n\n\nMLOps brings several benefits, including:\n\nEfficiency: By automating many steps in the ML lifecycle.\nReproducibility: By tracking every experiment with its data, code, and parameters.\nCollaboration: By enabling data scientists, data engineers, and DevOps to work together effectively.\nMonitoring: By continuously monitoring model performance and data quality.\nGovernance and regulatory compliance: By maintaining detailed logs of data, model predictions, and model changes.\n\nThe ultimate goal of MLOps is to accelerate the ML lifecycle and make ML models more valuable to the organization. Having a firm grasp of MLOps principles has been invaluable in my professional journey."
  },
  {
    "objectID": "Notes/MLOPS1.html",
    "href": "Notes/MLOPS1.html",
    "title": "Overview",
    "section": "",
    "text": "Dear Students,\nFollowing our introductory session on MLOps, today we will delve deeper into each component of the MLOps lifecycle and understand their practical applications.\n\n\nThe quality and consistency of data are critical for the performance of ML models. As such, versioning data is an important practice in MLOps. Tools like DVC can be used for this purpose. They keep track of changes in datasets and models, enabling you to reproduce any version of your experiment.\nAlso, don’t forget about data validation: tools like TensorFlow Data Validation (TFDV) can help you analyze and validate the consistency of your data over time.\n\n\n\nDuring this stage, data scientists build and train various machine learning models to solve the given problem. Key aspects of this stage are tracking experiments and ensuring reproducibility. An experiment involves a specific version of the code, a set of parameters, a dataset, and produces a model and its metrics. MLflow is a popular tool used to manage these experiments.\nTo ensure reproducibility, you must have version control in place for not just your code (using Git), but also your data and model (using tools like DVC or MLflow). Containerization technologies (like Docker) can also be used to maintain the consistency of the computing environment across different stages of the ML lifecycle.\n\n\n\nIn MLOps, testing isn’t limited to just the code; it also involves data testing and model validation.\n\nData Tests: These tests ensure that the data is in the correct format, within the expected range, and not corrupted.\nModel Tests: These tests confirm that the model is performing as expected and that its predictions make sense. Model validation techniques, like cross-validation or train/validation/test split, are used to assess the performance of the model.\n\n\n\n\nCI/CD are key DevOps practices that have been adapted for MLOps.\n\nContinuous Integration (CI): This involves regularly merging code changes into a central repository, after which automated builds and tests are run. CI ensures that the code remains in a deployable state and helps to catch bugs early.\nContinuous Deployment (CD): In CD, code changes are automatically deployed to production once they pass the necessary automated tests. In the context of MLOps, CD often involves deploying ML models to a serving infrastructure, which could be a server, a serverless platform, or an edge device.\n\nTools like Jenkins, Travis CI, or GitLab CI/CD are often used for implementing CI/CD pipelines.\n\n\n\nOnce the model is deployed, it’s important to continuously monitor its performance to ensure that it’s still providing valuable predictions as new data comes in. This can be achieved using monitoring tools like Prometheus or Grafana. Logging systems like Elasticsearch or Fluentd can help store detailed records of data inputs and outputs, model predictions, and any errors or exceptions.\n\n\n\nIn many industries, there are regulations requiring that models be explainable, fair, and unbiased. Thus, MLOps also involves applying techniques for model interpretability (like SHAP or LIME), and ensuring data privacy (like differential privacy or federated learning). Furthermore, maintaining detailed logs and implementing proper access control mechanisms can help meet regulatory compliance requirements.\nWe’ll continue exploring these components in our hands-on session where we’ll walk through the lifecycle of an ML project using popular MLOps tools.\nBest regards,\n[Your Name] Oxford University, Department of Computer Science"
  },
  {
    "objectID": "Notes/MLOPS3.html",
    "href": "Notes/MLOPS3.html",
    "title": "Overview",
    "section": "",
    "text": "Sure, while a full end-to-end example with code would be quite lengthy for this format, I can provide simplified examples for each of the key steps we discussed in the previous lecture. These examples will use Python and some popular libraries for each task."
  },
  {
    "objectID": "Notes/MLOPS3.html#setting-up-the-environment",
    "href": "Notes/MLOPS3.html#setting-up-the-environment",
    "title": "Overview",
    "section": "1. Setting up the Environment",
    "text": "1. Setting up the Environment\nYou can initialize a new Git repository and DVC project using the command line:\n# Initialize a Git repository\ngit init\n\n# Initialize a DVC project\ndvc init"
  },
  {
    "objectID": "Notes/MLOPS3.html#data-preparation",
    "href": "Notes/MLOPS3.html#data-preparation",
    "title": "Overview",
    "section": "2. Data Preparation",
    "text": "2. Data Preparation\nAssume you have a CSV file as your raw data. We’ll use pandas to clean and preprocess the data:\nimport pandas as pd\n\n# Load raw data\ndf = pd.read_csv('raw_data.csv')\n\n# Preprocess the data\ndf_clean = df.dropna()  # Drop missing values\ndf_clean.to_csv('clean_data.csv', index=False)\n\n# Add to DVC\n!dvc add clean_data.csv"
  },
  {
    "objectID": "Notes/MLOPS3.html#experimentation-and-model-building",
    "href": "Notes/MLOPS3.html#experimentation-and-model-building",
    "title": "Overview",
    "section": "3. Experimentation and Model Building",
    "text": "3. Experimentation and Model Building\nLet’s use sklearn for building a simple logistic regression model and mlflow for tracking the experiment:\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport mlflow\n\n# Load clean data\ndf_clean = pd.read_csv('clean_data.csv')\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df_clean.drop('target', axis=1), df_clean['target'], test_size=0.2)\n\n# Start an MLflow experiment\nwith mlflow.start_run():\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # Log model\n    mlflow.sklearn.log_model(model, \"model\")\n    \n    # Log metrics\n    mlflow.log_metric(\"accuracy\", model.score(X_test, y_test))"
  },
  {
    "objectID": "Notes/MLOPS3.html#testing",
    "href": "Notes/MLOPS3.html#testing",
    "title": "Overview",
    "section": "4. Testing",
    "text": "4. Testing\nYou can use pytest to create tests for your data and model:\nimport pytest\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\ndef test_data():\n    df = pd.read_csv('clean_data.csv')\n    assert not df.isnull().any().any(), \"Data contains null values.\"\n\ndef test_model():\n    df = pd.read_csv('clean_data.csv')\n    model = LogisticRegression()\n    model.fit(df.drop('target', axis=1), df['target'])\n    assert model.score(df.drop('target', axis=1), df['target']) > 0.8, \"Model accuracy is too low.\""
  },
  {
    "objectID": "Notes/MLOPS3.html#model-deployment",
    "href": "Notes/MLOPS3.html#model-deployment",
    "title": "Overview",
    "section": "5. Model Deployment",
    "text": "5. Model Deployment\nFor model deployment, you can save your model to a file and then load it in your serving code:\n# Save model to a file\nimport joblib\njoblib.dump(model, 'model.pkl')\n\n# Load model in serving code\nmodel = joblib.load('model.pkl')\nYou would then include this model file and the serving code in a Docker image."
  },
  {
    "objectID": "Notes/MLOPS3.html#monitoring",
    "href": "Notes/MLOPS3.html#monitoring",
    "title": "Overview",
    "section": "6. Monitoring",
    "text": "6. Monitoring\nPrometheus and Grafana are often used for monitoring, but they are typically used outside of your Python code, so we’ll skip the code example for this step."
  },
  {
    "objectID": "Notes/MLOPS3.html#maintenance-and-iteration",
    "href": "Notes/MLOPS3.html#maintenance-and-iteration",
    "title": "Overview",
    "section": "7. Maintenance and Iteration",
    "text": "7. Maintenance and Iteration\nIf the model performance drops, you would go back to the experimentation stage, adjust your model or data, and then rerun your code.\nRemember, these are simplified examples and real-world scenarios would involve more complex data preprocessing, model training, testing, and deployment steps."
  },
  {
    "objectID": "Notes/MLOPS2.html",
    "href": "Notes/MLOPS2.html",
    "title": "Overview",
    "section": "",
    "text": "Following our detailed discussion on MLOps components, it’s now time to put theory into practice. Today’s session will focus on implementing an end-to-end machine learning project using the MLOps principles we’ve learned.\nWe will use a mix of tools for different stages of the project, including DVC for data versioning, MLflow for experiment tracking, Jenkins for CI/CD, and Prometheus and Grafana for monitoring.\n\n\nFirstly, we’ll set up a collaborative environment with Git for version control. We will also set up DVC to track changes in our data and model files. All project members will clone the Git repository and set up DVC remotes.\n\n\n\nIn this step, we will prepare and explore the dataset. We’ll create scripts for data cleaning and preprocessing, ensuring we annotate them with proper comments for clarity. Once we have a processed dataset ready for ML modeling, we’ll use DVC to track the data file.\n\n\n\nNext, we will start building and training our models. It’s important to track the hyperparameters, metrics, and models for each experiment. We’ll use MLflow for this purpose. MLflow will allow us to compare different experiments and choose the best model for our problem.\n\n\n\nNow, we will create unit tests for our code, data validation tests for our dataset, and model validation tests for our model. For each code commit, these tests will run automatically in our Jenkins CI/CD pipeline.\n\n\n\nOnce we have a model that performs well and passes all tests, it’s time to deploy it. We’ll create a Docker image that includes our model and the necessary serving code, and we’ll configure Jenkins to deploy this image automatically to our serving infrastructure.\n\n\n\nAfter deployment, we need to monitor the model’s performance in real-time. We will set up Prometheus to collect metrics from our model server, and we’ll use Grafana to create a dashboard for viewing these metrics.\n\n\n\nMLOps is not a one-time setup; it’s a continuous process. We’ll set up alerts to inform us when our model’s performance drops below a certain threshold. If that happens, or if we receive new data, we’ll iterate on our models: we’ll go back to the experimentation stage, make improvements, and push the changes through our CI/CD pipeline.\nRemember, MLOps is about managing the lifecycle of machine learning projects in a way that promotes collaboration, efficiency, and reliability. The tools and techniques we’re learning in this course will serve you well in your future data science endeavors.\nIn the next session, we’ll get hands-on with these tools, and you’ll have the opportunity to set up your own MLOps pipelines.\nBest regards,\n[Your Name] Oxford University, Department of Computer Science"
  },
  {
    "objectID": "products.html#selected-projects-over-the-last-2-years",
    "href": "products.html#selected-projects-over-the-last-2-years",
    "title": "Projects",
    "section": "Selected projects over the last 2 years",
    "text": "Selected projects over the last 2 years\n\nPredicting Market Direction for Cocoa Futures\nBased on supply and demand data as well as key weather events I built time series models in order to predict the direction of price changes in futures contracts for cocoa in London and New York. I used prophet library and Keras, using recurrent neural networks. This model is used by traders in ECOM on a daily basis.\n\n\nPredicting Cocoa Production\nIn this project I used climatic variables to predict the yield of two crop seasons for cocoa in Côte d’Ivore. The model was a series of ensemble models that weighted the anomalies for each week/month and adjusted the forecast. The predictions have been tested over the last 2 years (4 seasons) with accurate results, even with models with early information.\n\n\nPredicting loss of suitability of coffee and cocoa due to climate change\nClimate change is having a major impact on the production of cocoa and coffee around the world. I used several models (Random Forest, Neural Networks and XGBoost) to model the current suitability of cocoa and coffee using several climatic variables. Once the model was calibrated on current conditions, the predictions were applied to future conditions to understand either the expansion or contraction of the areas of production that are suitable today. The results of these models has helped to develop the priorities to mitigate dramatic changes in the tropics.\n\n\nAmex Default Prediction\nI used this data to train junior peers to show them how to use different classification methods to extract value of large datasets. The data came from a Kaggle competition. I used gradient boosting decision trees. Specifically, I trained and evaluated the LGBMClassifier, XGBClassifier and the CatBoostClassifier models with gold standard results in the context of the competition to successfully identify whether a customer would default on their repayments of credit."
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Reinforcement Learning (RL) is a subfield of machine learning that focuses on how an agent ought to take actions in an environment to maximize some notion of cumulative reward. In this tutorial, we will go over the fundamental principles of RL and how to implement them in Python and R.\n\n\nRL revolves around these main concepts:\n\nAgent: The RL algorithm that learns from trial and error.\nEnvironment: The context where the agent operates.\nState: The current situation of the agent.\nAction: All possible moves the agent can make.\nReward: Feedback from the environment.\n\nThe agent learns by interacting with its environment, it takes actions, the environment returns the new state and gives a reward. The goal of the agent is to maximize the sum of rewards.\n\n\n\nOne of the simplest ways to understand reinforcement learning is through Q-Learning. The objective of Q-Learning is to find a policy that is optimal in the sense that the expected value of the total reward over all successive steps is maximized.\nThe Q-Learning algorithm uses a table (Q-table) where we have a row for each state (s) and a column for each action (a). The cell at the intersection of state (s) and action (a) represents the expected future reward that the agent will get if it takes action (a) while in state (s).\nLet’s start with the Python implementation of Q-learning.\n\n\n\nFor our Python implementation, we will use the OpenAI Gym environment, which provides different game scenarios for training reinforcement learning agents. We’ll work with the FrozenLake-v0 game.\nimport numpy as np\nimport gym\nimport random\nimport time\nfrom IPython.display import clear_output\n\n# Create the environment\nenv = gym.make(\"FrozenLake-v0\")\n\n# Initialize Q-table with zero\nq_table = np.zeros([env.observation_space.n, env.action_space.n])\n\n# Hyperparameters\nnum_episodes = 10000\nmax_steps_per_episode = 100\n\nlearning_rate = 0.1\ndiscount_rate = 0.99\n\nexploration_rate = 1\nmax_exploration_rate = 1\nmin_exploration_rate = 0.01\nexploration_decay_rate = 0.001\n\nrewards_all_episodes = []\n\n# Q-learning algorithm\nfor episode in range(num_episodes):\n    state = env.reset()\n\n    done = False\n    rewards_current_episode = 0\n\n    for step in range(max_steps_per_episode): \n        exploration_rate_threshold = random.uniform(0, 1)\n        if exploration_rate_threshold > exploration_rate:\n            action = np.argmax(q_table[state,:]) \n        else:\n            action = env.action_space.sample()\n\n        new_state, reward, done, info = env.step(action)\n\n        # Update Q-table for Q(s,a)\n        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n            learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n\n        state = new_state\n        rewards_current_episode += reward \n\n        if done == True: \n            break\n\n    # Exploration rate decay\n    exploration_rate = min_exploration_rate + \\\n        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n\n    rewards_all_episodes.append(rewards_current_episode)\nThis code creates an agent that learns to play\nthe FrozenLake-v0 game. The agent uses Q-Learning to learn how to play.\n\n\n\nNow let’s implement the same Q-Learning in R. We’re going to make a simple grid world with four cells, where the agent needs to find the terminal state to get a reward.\nlibrary(MDPtoolbox)\n\n# Define transition and reward matrices\nS <- 4\nA <- 2\nT <- array(0, c(S, A, S))\nR <- matrix(0, S, A)\n\n# Define transitions\nT[1, 1, 2] <- 1\nT[2, 1, 3] <- 1\nT[3, 1, 4] <- 1\nT[4, 1, 4] <- 1\n\nT[1, 2, 1] <- 1\nT[2, 2, 1] <- 1\nT[3, 2, 2] <- 1\nT[4, 2, 3] <- 1\n\n# Define rewards\nR[3, 1] <- 1\nR[4, 1] <- 1\n\n# Run Q-Learning\nresult <- mdp_example_qlearning(T, R, 0.9, 10000)\nThe code above creates a simple environment using the MDPtoolbox library. The environment is a simple four-state system where the agent learns to navigate to the terminal state using Q-Learning.\n\n\n\nReinforcement learning is a powerful approach for tasks that involve sequential decision-making. This tutorial presented the fundamental concepts of RL and walked through an example of how to implement Q-Learning, a simple but powerful RL algorithm, in Python and R. Remember that the RL field is vast and complex, this is just the tip of the iceberg!\nThis tutorial is intended as a starting point. I encourage you to continue exploring more complex environments, policies, and algorithms as you continue your journey in reinforcement learning. Happy learning!"
  },
  {
    "objectID": "skills.html",
    "href": "skills.html",
    "title": "Skills",
    "section": "",
    "text": "Python (most used libraries: Pandas, GeoPandas, prophet, SciKit-Learn, TensorFlow, Pytorch, keras, Matplotlib, NumPy, SciPy, SQLAlchemy, Seaborn, Bokeh, SciKit-Images)\nR (most used packages: RStudio, Shiny, tidyverse, Parsnip, bayestestR, sparklyr, keras, dygraph, forecast)"
  },
  {
    "objectID": "skills.html#geospatial-analysis",
    "href": "skills.html#geospatial-analysis",
    "title": "Skills",
    "section": "Geospatial analysis",
    "text": "Geospatial analysis\nAdvanced skills in ArcGIS and QGIS"
  },
  {
    "objectID": "skills.html#big-data-databases",
    "href": "skills.html#big-data-databases",
    "title": "Skills",
    "section": "Big Data & Databases",
    "text": "Big Data & Databases\nProficient in SQL, MongoDB (NoSQL), Spark (pyspark and sparklyr)"
  },
  {
    "objectID": "skills.html#experimental-design",
    "href": "skills.html#experimental-design",
    "title": "Skills",
    "section": "Experimental design",
    "text": "Experimental design\nStrong background designing and implementing A/B tests, machine learning algorithms (supervised and unsupervised) and Bayesian statistics"
  },
  {
    "objectID": "skills.html#languages",
    "href": "skills.html#languages",
    "title": "Skills",
    "section": "Languages",
    "text": "Languages\nFluent in English and Spanish (native)"
  },
  {
    "objectID": "Tutorials/Forecasting.html",
    "href": "Tutorials/Forecasting.html",
    "title": "Forecasting with Time Series Methods: A Comparative Approach using R and Python",
    "section": "",
    "text": "When it comes to predicting future trends, events, or quantities—known as forecasting—time series methods are some of the most commonly used approaches. By definition, a time series is a sequence of data points recorded at successive, equally spaced intervals. Given the unique traits of time series data, specialized analysis techniques have been developed over time, and these methods can be used to forecast future data points.\nIn this blog post, we will look at how to apply time series methods to forecast data using two popular programming languages: R and Python.\n\n\nBefore delving into the coding aspect, it’s important to understand the key components of a time series:\n\nTrend: The underlying pattern of growth or decline in a time series.\nSeasonality: Regular and predictable changes that recur every calendar year.\nCyclical components: Fluctuations happening due to economic cycles.\nIrregular (or residual) component: The random variation in the series.\n\n\n\n\nR provides robust support for time series analysis via several specialized packages like forecast, tseries, and tsibble.\nIn this example, we will use the forecast package to analyze the AirPassengers dataset.\n\n# Loading required library\n\nlibrary(forecast)\n\n# Load the dataset\n\ndata(AirPassengers)\n\n# Plotting the data\n\nplot(AirPassengers)\n\n# Decomposing the time series\n\ndecomposed_ap <- decompose(AirPassengers)\n\n# Plotting the decomposed time series\n\nplot(decomposed_ap)\n\n# Applying the ARIMA model\n\narima_model <- auto.arima(AirPassengers)\n\n# Forecasting for next 24 months\n\nforecast_arima <- forecast(arima_model, h=24)\n\n# Plotting the forecast\n\nplot(forecast_arima)\nIn this example, we first decomposed the time series to understand its underlying components. We then fitted an ARIMA model using the auto.arima() function, and used it to forecast the next 24 months.\n\n\n\nPython also has strong support for time series analysis, particularly through the pandas and statsmodels libraries.\nLet’s analyze the same AirPassengers dataset in Python.\n\n# Importing required libraries\n\nimport pandas as pd\n\nimport numpy as np\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom statsmodels.tsa.arima.model import ARIMA\n\nimport matplotlib.pyplot as plt\n\n# Load the dataset\n\nair_passengers = pd.read_csv('AirPassengers.csv', parse_dates=['Month'], index_col='Month')\n\n# Plotting the data\n\nair_passengers.plot()\n\n# Decomposing the time series\n\ndecomposition = seasonal_decompose(air_passengers)\n\n# Plotting the decomposed time series\n\ndecomposition.plot()\n\nplt.show()\n\n# Applying the ARIMA model\n\nmodel = ARIMA(air_passengers, order=(5,1,0))\n\nmodel_fit = model.fit(disp=0)\n\n# Forecasting for next 24 months\n\nforecast, stderr, conf_int = model_fit.forecast(steps=24)\n\n# Plotting the forecast\n\nplt.plot(forecast)\n\nplt.fill_between(range(len(forecast)), forecast - stderr, forecast + stderr, color='r', alpha=.1)\n\nplt.show()\nHere, we used the seasonal_decompose() function from statsmodels to decompose the time series, fitted an ARIMA model, and made a forecast for the next 24 months.\n\n\n\nIn summary, time series forecasting is a powerful tool for\npredicting future trends and events. Both R and Python provide excellent support for time series analysis and can be chosen based on the specific requirements of your project and your familiarity with the language. Happy forecasting!"
  },
  {
    "objectID": "Tutorials/RL.html",
    "href": "Tutorials/RL.html",
    "title": "Tutorials",
    "section": "",
    "text": "Reinforcement Learning (RL) is a subfield of machine learning that focuses on how an agent ought to take actions in an environment to maximize some notion of cumulative reward. In this tutorial, we will go over the fundamental principles of RL and how to implement them in Python and R.\n\n\nRL revolves around these main concepts:\n\nAgent: The RL algorithm that learns from trial and error.\nEnvironment: The context where the agent operates.\nState: The current situation of the agent.\nAction: All possible moves the agent can make.\nReward: Feedback from the environment.\n\nThe agent learns by interacting with its environment, it takes actions, the environment returns the new state and gives a reward. The goal of the agent is to maximize the sum of rewards.\n\n\n\nOne of the simplest ways to understand reinforcement learning is through Q-Learning. The objective of Q-Learning is to find a policy that is optimal in the sense that the expected value of the total reward over all successive steps is maximized.\nThe Q-Learning algorithm uses a table (Q-table) where we have a row for each state (s) and a column for each action (a). The cell at the intersection of state (s) and action (a) represents the expected future reward that the agent will get if it takes action (a) while in state (s).\nLet’s start with the Python implementation of Q-learning.\n\n\n\nFor our Python implementation, we will use the OpenAI Gym environment, which provides different game scenarios for training reinforcement learning agents. We’ll work with the FrozenLake-v0 game.\nimport numpy as np\nimport gym\nimport random\nimport time\nfrom IPython.display import clear_output\n\n# Create the environment\nenv = gym.make(\"FrozenLake-v0\")\n\n# Initialize Q-table with zero\nq_table = np.zeros([env.observation_space.n, env.action_space.n])\n\n# Hyperparameters\nnum_episodes = 10000\nmax_steps_per_episode = 100\n\nlearning_rate = 0.1\ndiscount_rate = 0.99\n\nexploration_rate = 1\nmax_exploration_rate = 1\nmin_exploration_rate = 0.01\nexploration_decay_rate = 0.001\n\nrewards_all_episodes = []\n\n# Q-learning algorithm\nfor episode in range(num_episodes):\n    state = env.reset()\n\n    done = False\n    rewards_current_episode = 0\n\n    for step in range(max_steps_per_episode): \n        exploration_rate_threshold = random.uniform(0, 1)\n        if exploration_rate_threshold > exploration_rate:\n            action = np.argmax(q_table[state,:]) \n        else:\n            action = env.action_space.sample()\n\n        new_state, reward, done, info = env.step(action)\n\n        # Update Q-table for Q(s,a)\n        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n            learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n\n        state = new_state\n        rewards_current_episode += reward \n\n        if done == True: \n            break\n\n    # Exploration rate decay\n    exploration_rate = min_exploration_rate + \\\n        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n\n    rewards_all_episodes.append(rewards_current_episode)\nThis code creates an agent that learns to play\nthe FrozenLake-v0 game. The agent uses Q-Learning to learn how to play.\n\n\n\nNow let’s implement the same Q-Learning in R. We’re going to make a simple grid world with four cells, where the agent needs to find the terminal state to get a reward.\nlibrary(MDPtoolbox)\n\n# Define transition and reward matrices\nS <- 4\nA <- 2\nT <- array(0, c(S, A, S))\nR <- matrix(0, S, A)\n\n# Define transitions\nT[1, 1, 2] <- 1\nT[2, 1, 3] <- 1\nT[3, 1, 4] <- 1\nT[4, 1, 4] <- 1\n\nT[1, 2, 1] <- 1\nT[2, 2, 1] <- 1\nT[3, 2, 2] <- 1\nT[4, 2, 3] <- 1\n\n# Define rewards\nR[3, 1] <- 1\nR[4, 1] <- 1\n\n# Run Q-Learning\nresult <- mdp_example_qlearning(T, R, 0.9, 10000)\nThe code above creates a simple environment using the MDPtoolbox library. The environment is a simple four-state system where the agent learns to navigate to the terminal state using Q-Learning.\n\n\n\nReinforcement learning is a powerful approach for tasks that involve sequential decision-making. This tutorial presented the fundamental concepts of RL and walked through an example of how to implement Q-Learning, a simple but powerful RL algorithm, in Python and R. Remember that the RL field is vast and complex, this is just the tip of the iceberg!\nThis tutorial is intended as a starting point. I encourage you to continue exploring more complex environments, policies, and algorithms as you continue your journey in reinforcement learning. Happy learning!"
  }
]